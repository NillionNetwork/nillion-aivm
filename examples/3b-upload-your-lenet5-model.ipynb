{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIVM Tutorial: Uploading Custom Models to AIVM\n",
    "\n",
    "This tutorial demonstrates how to upload and use custom models with the AIVM (AI Virtual Machine) system, focusing on a BERT-tiny model for SMS spam detection.\n",
    "\n",
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import time\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import aivm_client as aic # Import the Nillion-AIVM client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell imports the required Python libraries for:\n",
    "- Neural network operations (`torch`)\n",
    "- Dataset handling (`torchvision`)\n",
    "- Visualization (`matplotlib`)\n",
    "- AIVM client interface (`aivm_client`)\n",
    "\n",
    "## Model Upload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"LeNet5CatsDogs\" # Name of the model to be used\n",
    "aic.upload_lenet5_model(\"./cats_dogs_lenet5.pth\", MODEL_NAME) # Upload the model to the server\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell demonstrates how to upload a custom model to the AIVM server:\n",
    "1. Define a unique name for the model\n",
    "2. Upload an Pytorch-format model file using the AIVM client\n",
    "3. The model will be available for encrypted inference after upload\n",
    "\n",
    "## CAT-DOG Classification Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define transformation: Resize to 28x28 and convert to grayscale\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),  # Resize to 28x28\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.ToTensor(),  # Convert image to Tensor\n",
    "    transforms.Normalize((0.5,), (1.0,))\n",
    "])\n",
    "\n",
    "ds = load_dataset(\"microsoft/cats_vs_dogs\")\n",
    "\n",
    "\n",
    "img_tensor = transform(ds[\"train\"][1][\"image\"])\n",
    "\n",
    "encrypted_input = aic.LeNet5Cryptensor(img_tensor.reshape(1, 1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell prepares the input text for spam detection:\n",
    "1. Loads the example from the dataset and transforms it\n",
    "2. Creates an encrypted tensor from the transformed input\n",
    "\n",
    "## Encrypted Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = aic.get_prediction(encrypted_input, MODEL_NAME)\n",
    "print(\"CAT\" if torch.argmax(prediction).item() == 0 else \"DOG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell:\n",
    "1. Performs encrypted inference using our uploaded custom model\n",
    "2. Measures the execution time\n",
    "3. Returns the raw model output (logits)\n",
    "\n",
    "Output shows:\n",
    "- CPU usage statistics\n",
    "- Wall time for inference\n",
    "- Tensor with prediction scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell interprets the model's prediction:\n",
    "- Converts numerical output to a binary classification\n",
    "- Tells whether a review is positive or negative\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "1. **Model Management**\n",
    "   - Custom models can be uploaded to AIVM in PyTorch format\n",
    "   - Models are referenced by unique names\n",
    "   - Uploaded models persist on the server for future use\n",
    "\n",
    "2. **Privacy-Preserving Inference**\n",
    "   - All inference is performed on encrypted data\n",
    "   - Model weights and architecture remain secure\n",
    "   - Results are only decrypted at the client side\n",
    "\n",
    "3. **Performance Considerations**\n",
    "   - Encrypted computation introduces some overhead\n",
    "   - Wall time measurements help evaluate real-world performance\n",
    "   - System is optimized for practical use cases\n",
    "\n",
    "4. **Integration Workflow**\n",
    "   1. Upload model\n",
    "   2. Prepare and encrypt inputs\n",
    "   3. Perform inference\n",
    "   4. Interpret results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
